---
phase: 02-audio-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - entrypoints/background.ts
  - entrypoints/offscreen/main.ts
autonomous: true

must_haves:
  truths:
    - "Popup click triggers tab audio capture via Service Worker"
    - "Service Worker gets stream ID via tabCapture.getMediaStreamId()"
    - "Offscreen Document creates MediaStream from stream ID"
    - "Tab audio remains audible during capture (passthrough)"
    - "PCM chunks flow from AudioWorklet to message system"
  artifacts:
    - path: "entrypoints/background.ts"
      provides: "Tab capture handler with stream ID retrieval"
      contains: "tabCapture.getMediaStreamId"
    - path: "entrypoints/offscreen/main.ts"
      provides: "Audio capture with passthrough"
      contains: "chromeMediaSource"
  key_links:
    - from: "entrypoints/background.ts"
      to: "entrypoints/offscreen/main.ts"
      via: "TAB_STREAM_ID message"
      pattern: "TAB_STREAM_ID"
    - from: "entrypoints/offscreen/main.ts"
      to: "audioContext.destination"
      via: "connect for passthrough"
      pattern: "connect\\(.*destination\\)"
---

<objective>
Implement tab audio capture in the Service Worker and Offscreen Document, with audio passthrough so users can still hear the tab.

Purpose: Enable capturing tab audio (interviewer's voice from Google Meet) while maintaining audibility - the core AUD-01 and AUD-03 requirements.
Output: Extended background.ts with tabCapture handling, extended offscreen/main.ts with audio capture and passthrough.
</objective>

<execution_context>
@/Users/sasha-marchuk/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sasha-marchuk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-audio-pipeline/02-RESEARCH.md
@.planning/phases/02-audio-pipeline/02-01-SUMMARY.md

@src/types/messages.ts
@entrypoints/background.ts
@entrypoints/offscreen/main.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add tab capture handler to Service Worker</name>
  <files>entrypoints/background.ts</files>
  <action>
Extend background.ts to handle START_CAPTURE and STOP_CAPTURE messages:

1. Import new message types from messages.ts (StartCaptureMessage, TabStreamIdMessage, etc.)

2. Add handler for START_CAPTURE in handleMessage():
   - Get the active tab ID using chrome.tabs.query({ active: true, currentWindow: true })
   - Call chrome.tabCapture.getMediaStreamId({ targetTabId: tabId })
   - This MUST be called in user gesture context (popup click propagates)
   - Ensure offscreen document exists (call ensureOffscreenDocument())
   - Send TAB_STREAM_ID message to runtime with the streamId
   - Return { success: true } or throw on error

3. Add handler for STOP_CAPTURE:
   - Send STOP_CAPTURE to runtime (offscreen will handle cleanup)
   - Return { success: true }

4. Add handler for TAB_AUDIO_CHUNK (from offscreen):
   - Log chunk received with timestamp (for Phase 2 verification)
   - Later phases will forward to transcription service
   - Return { received: true }

5. Add handler for CAPTURE_STARTED, CAPTURE_STOPPED, CAPTURE_ERROR:
   - Log state changes for debugging
   - Return { received: true }

IMPORTANT: tabCapture.getMediaStreamId() requires "tabCapture" permission - verify in wxt.config.ts manifest permissions.

Error handling: Wrap tabCapture call in try/catch, return CAPTURE_ERROR message on failure.
  </action>
  <verify>
TypeScript compiles:
```bash
cd /Users/sasha-marchuk/Work/Ai-Interview-Assistant-Chrome-Extension && npx tsc --noEmit
```
Build succeeds:
```bash
cd /Users/sasha-marchuk/Work/Ai-Interview-Assistant-Chrome-Extension && npm run build
```
  </verify>
  <done>Service Worker handles START_CAPTURE by getting stream ID and forwarding to offscreen</done>
</task>

<task type="auto">
  <name>Task 2: Implement tab audio capture in Offscreen Document</name>
  <files>entrypoints/offscreen/main.ts</files>
  <action>
Extend offscreen/main.ts to handle audio capture:

1. Import audio message types from messages.ts

2. Add module-level state:
   - let audioContext: AudioContext | null = null
   - let tabStream: MediaStream | null = null
   - let workletNode: AudioWorkletNode | null = null

3. Create startTabCapture(streamId: string) async function:
   a. Get MediaStream using navigator.mediaDevices.getUserMedia with constraints:
      {
        audio: {
          mandatory: {
            chromeMediaSource: 'tab',
            chromeMediaSourceId: streamId
          }
        },
        video: false
      }
   b. Create AudioContext with { sampleRate: 16000 }
   c. Log actual sampleRate (browser may not honor request)
   d. Create MediaStreamSource from tabStream
   e. CRITICAL: Connect source to audioContext.destination (passthrough)
   f. Load AudioWorklet module: await audioContext.audioWorklet.addModule(chrome.runtime.getURL('pcm-processor.js'))
   g. Create AudioWorkletNode with processor name 'pcm-processor'
   h. Connect source to workletNode
   i. Set workletNode.port.onmessage to send TAB_AUDIO_CHUNK messages:
      chrome.runtime.sendMessage({
        type: 'TAB_AUDIO_CHUNK',
        chunk: event.data,
        timestamp: Date.now()
      })
   j. Send CAPTURE_STARTED message

4. Create stopTabCapture() function:
   a. Stop all tracks on tabStream
   b. Disconnect workletNode
   c. Close audioContext
   d. Set all to null
   e. Send CAPTURE_STOPPED message

5. Add message handlers:
   - TAB_STREAM_ID: Call startTabCapture(message.streamId)
   - STOP_CAPTURE: Call stopTabCapture()

6. Wrap all operations in try/catch, send CAPTURE_ERROR on failure

IMPORTANT: TypeScript may complain about chromeMediaSource constraint - use type assertion or add to global types. This is a Chrome-specific constraint not in standard TypeScript definitions.
  </action>
  <verify>
TypeScript compiles:
```bash
cd /Users/sasha-marchuk/Work/Ai-Interview-Assistant-Chrome-Extension && npx tsc --noEmit
```
Build succeeds:
```bash
cd /Users/sasha-marchuk/Work/Ai-Interview-Assistant-Chrome-Extension && npm run build
```
Check pcm-processor.js is in output:
```bash
ls -la /Users/sasha-marchuk/Work/Ai-Interview-Assistant-Chrome-Extension/.output/chrome-mv3/ | grep pcm
```
  </verify>
  <done>Offscreen Document captures tab audio, routes to destination (passthrough), sends PCM chunks via messages</done>
</task>

<task type="auto">
  <name>Task 3: Add tabCapture permission to manifest</name>
  <files>wxt.config.ts</files>
  <action>
Verify and add tabCapture permission in wxt.config.ts:

1. Check if manifest.permissions already includes "tabCapture"
2. If not, add "tabCapture" to the permissions array
3. Verify "offscreen" permission is present (should be from Phase 1)

The manifest section should include at minimum:
```typescript
manifest: {
  permissions: [
    "offscreen",
    "tabCapture"
  ],
  // ... rest of manifest
}
```

Note: tabCapture permission doesn't require host_permissions - it captures the tab the user is viewing.
  </action>
  <verify>
Check manifest in build output:
```bash
grep -A 10 '"permissions"' /Users/sasha-marchuk/Work/Ai-Interview-Assistant-Chrome-Extension/.output/chrome-mv3/manifest.json
```
  </verify>
  <done>tabCapture permission present in manifest, extension can capture tab audio</done>
</task>

</tasks>

<verification>
1. TypeScript compiles: `npx tsc --noEmit`
2. Build succeeds: `npm run build`
3. pcm-processor.js exists in build output
4. tabCapture permission in manifest.json
5. Offscreen document has chromeMediaSource constraint handling
6. Audio routing includes connect(destination) for passthrough
</verification>

<success_criteria>
- Service Worker gets stream ID via tabCapture.getMediaStreamId()
- Offscreen Document creates MediaStream from stream ID
- Audio passthrough via connect(destination) prevents muting
- PCM chunks sent as TAB_AUDIO_CHUNK messages
- Build produces valid extension with all required permissions
</success_criteria>

<output>
After completion, create `.planning/phases/02-audio-pipeline/02-02-SUMMARY.md`
</output>
