---
phase: 02-audio-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/types/messages.ts
  - public/pcm-processor.js
autonomous: true

must_haves:
  truths:
    - "Audio message types exist for capture lifecycle"
    - "PCM processor converts Float32 audio to 16-bit Int16"
    - "Processor buffers and sends 100ms chunks"
  artifacts:
    - path: "src/types/messages.ts"
      provides: "Audio capture message types"
      contains: "START_CAPTURE"
    - path: "public/pcm-processor.js"
      provides: "AudioWorklet processor"
      contains: "registerProcessor"
  key_links:
    - from: "public/pcm-processor.js"
      to: "AudioWorklet API"
      via: "registerProcessor call"
      pattern: "registerProcessor\\('pcm-processor'"
---

<objective>
Define message types for audio capture lifecycle and create the AudioWorklet PCM processor that converts Float32 audio samples to 16-bit PCM Int16 format.

Purpose: Establish the communication contract and audio processing foundation that all subsequent audio plans depend on.
Output: Extended message types in messages.ts, vanilla JS AudioWorklet processor in public folder.
</objective>

<execution_context>
@/Users/sasha-marchuk/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sasha-marchuk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-audio-pipeline/02-RESEARCH.md

@src/types/messages.ts
@entrypoints/background.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend message types for audio capture</name>
  <files>src/types/messages.ts</files>
  <action>
Add audio capture message types to the existing message system:

1. Add to MessageType union:
   - 'START_CAPTURE' - Popup requests capture start
   - 'STOP_CAPTURE' - Popup requests capture stop
   - 'CAPTURE_STARTED' - Offscreen confirms capture active
   - 'CAPTURE_STOPPED' - Offscreen confirms capture ended
   - 'CAPTURE_ERROR' - Offscreen reports error
   - 'TAB_STREAM_ID' - Service Worker sends stream ID to Offscreen
   - 'TAB_AUDIO_CHUNK' - Offscreen sends PCM chunk
   - 'MIC_AUDIO_CHUNK' - Offscreen sends microphone PCM chunk

2. Create interface for each:
   - StartCaptureMessage: { type: 'START_CAPTURE' }
   - StopCaptureMessage: { type: 'STOP_CAPTURE' }
   - CaptureStartedMessage: { type: 'CAPTURE_STARTED' }
   - CaptureStoppedMessage: { type: 'CAPTURE_STOPPED' }
   - CaptureErrorMessage: { type: 'CAPTURE_ERROR', error: string }
   - TabStreamIdMessage: { type: 'TAB_STREAM_ID', streamId: string }
   - AudioChunkMessage: { type: 'TAB_AUDIO_CHUNK' | 'MIC_AUDIO_CHUNK', chunk: ArrayBuffer, timestamp: number }

3. Add to ExtensionMessage union type
4. Keep existing isMessage type guard - it will work with new types

IMPORTANT: Follow existing code patterns - BaseMessage extension, discriminated union.
  </action>
  <verify>
TypeScript compiles without errors:
```bash
cd /Users/sasha-marchuk/Work/Ai-Interview-Assistant-Chrome-Extension && npx tsc --noEmit
```
  </verify>
  <done>Message types cover complete audio capture lifecycle (start, stop, errors, data chunks)</done>
</task>

<task type="auto">
  <name>Task 2: Create AudioWorklet PCM processor</name>
  <files>public/pcm-processor.js</files>
  <action>
Create vanilla JavaScript AudioWorklet processor file:

1. Create PCMProcessor class extending AudioWorkletProcessor
2. In constructor:
   - Initialize empty buffer array
   - Set bufferSize to 1600 (100ms at 16kHz sample rate)
3. Add floatTo16BitPCM(sample) helper:
   - Clamp sample to [-1, 1]
   - Convert: sample < 0 ? sample * 0x8000 : sample * 0x7FFF
   - Return integer value
4. Implement process(inputs, outputs, parameters):
   - Get first input, first channel (mono)
   - Return true immediately if no input
   - Loop through samples, convert to Int16, push to buffer
   - When buffer.length >= bufferSize, splice chunk and postMessage
   - Use transferable ArrayBuffer: this.port.postMessage(chunk.buffer, [chunk.buffer])
   - Always return true to keep processor alive
5. Register processor: registerProcessor('pcm-processor', PCMProcessor)

IMPORTANT: Must be vanilla JS (not TypeScript). AudioWorklet runs in separate thread with no module resolution.

Use `sampleRate` global (available in AudioWorklet scope) for dynamic buffer sizing if needed, but default to 1600 for 16kHz.
  </action>
  <verify>
File exists and has correct structure:
```bash
cat /Users/sasha-marchuk/Work/Ai-Interview-Assistant-Chrome-Extension/public/pcm-processor.js | head -50
```
Verify registerProcessor call present:
```bash
grep -n "registerProcessor" /Users/sasha-marchuk/Work/Ai-Interview-Assistant-Chrome-Extension/public/pcm-processor.js
```
  </verify>
  <done>PCM processor exists, converts Float32 to Int16, buffers 100ms chunks, transfers via postMessage</done>
</task>

</tasks>

<verification>
1. TypeScript compiles without errors: `npx tsc --noEmit`
2. public/pcm-processor.js exists and contains registerProcessor('pcm-processor', ...)
3. Message types include START_CAPTURE, STOP_CAPTURE, CAPTURE_STARTED, CAPTURE_STOPPED, CAPTURE_ERROR, TAB_STREAM_ID, TAB_AUDIO_CHUNK, MIC_AUDIO_CHUNK
</verification>

<success_criteria>
- All new message types are defined with proper TypeScript interfaces
- PCM processor is valid JavaScript that can be loaded by AudioWorklet
- Existing extension functionality not broken (build still succeeds)
</success_criteria>

<output>
After completion, create `.planning/phases/02-audio-pipeline/02-01-SUMMARY.md`
</output>
