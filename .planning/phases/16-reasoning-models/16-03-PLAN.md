---
phase: 16-reasoning-models
plan: 03
type: execute
wave: 3
depends_on: ["16-01", "16-02"]
files_modified:
  - src/overlay/Overlay.tsx
  - src/overlay/OverlayHeader.tsx
  - src/overlay/ResponsePanel.tsx
  - src/components/settings/ModelSettings.tsx
  - entrypoints/content.tsx
autonomous: true

must_haves:
  truths:
    - "User sees a Reasoning button in the overlay that triggers a single-stream reasoning request"
    - "User can select reasoning effort level (low/medium/high) near the reasoning button"
    - "When a reasoning request is in progress, the status shows 'Reasoning...' with a purple indicator"
    - "User can select o4-mini, GPT-5 series, and other reasoning models in the ModelSettings dropdowns"
    - "ModelSettings visually groups reasoning models separately from standard models"
  artifacts:
    - path: "src/overlay/Overlay.tsx"
      provides: "Reasoning button and reasoning effort selector in overlay"
      contains: "Reason"
    - path: "src/overlay/ResponsePanel.tsx"
      provides: "Reasoning status indicator with purple theme"
      contains: "Reasoning"
    - path: "src/components/settings/ModelSettings.tsx"
      provides: "Reasoning model group in model picker"
      contains: "Reasoning"
    - path: "entrypoints/content.tsx"
      provides: "sendReasoningRequest function dispatching LLM_REQUEST with reasoning flags"
      contains: "isReasoningRequest"
  key_links:
    - from: "src/overlay/Overlay.tsx"
      to: "entrypoints/content.tsx"
      via: "reasoning-request custom event dispatched by button, handled by content script"
      pattern: "reasoning-request"
    - from: "entrypoints/content.tsx"
      to: "entrypoints/background.ts"
      via: "sends LLM_REQUEST with isReasoningRequest=true"
      pattern: "isReasoningRequest.*true"
    - from: "src/overlay/Overlay.tsx"
      to: "src/store/types.ts"
      via: "reads reasoningEffort from store"
      pattern: "reasoningEffort"
---

<objective>
Add reasoning UI controls to the overlay (reasoning button, effort selector, thinking indicator) and update ModelSettings to properly display reasoning models. Wire the reasoning button through content.tsx to dispatch reasoning requests.

Purpose: This is the user-facing part of Phase 16. Without these UI controls, users cannot trigger reasoning model requests or control reasoning effort. The button provides a dedicated one-click path to reasoning, separate from the normal hold-to-capture dual-stream flow.

Output: Fully functional reasoning button, effort selector, thinking indicator, and updated model settings UI.
</objective>

<execution_context>
@/Users/sasha-marchuk/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sasha-marchuk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/16-reasoning-models/16-RESEARCH.md
@.planning/phases/16-reasoning-models/16-01-SUMMARY.md
@.planning/phases/16-reasoning-models/16-02-SUMMARY.md

@src/overlay/Overlay.tsx
@src/overlay/OverlayHeader.tsx
@src/overlay/ResponsePanel.tsx
@src/components/settings/ModelSettings.tsx
@entrypoints/content.tsx
@src/types/transcript.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add reasoning button, effort selector, and thinking indicator to overlay</name>
  <files>
    src/overlay/Overlay.tsx
    src/overlay/OverlayHeader.tsx
    src/overlay/ResponsePanel.tsx
  </files>
  <action>
    **OverlayHeader.tsx -- add reasoning button and effort selector:**
    1. Accept new props:
       ```typescript
       interface OverlayHeaderProps {
         onMinimize: () => void;
         onReasoningRequest: () => void;
         reasoningEffort: 'low' | 'medium' | 'high';
         onReasoningEffortChange: (effort: 'low' | 'medium' | 'high') => void;
       }
       ```
    2. Add a "Reason" button next to the minimize button, styled with purple theme:
       ```tsx
       <div className="flex items-center gap-1">
         {/* Reasoning effort selector - small dropdown */}
         <select
           value={reasoningEffort}
           onChange={(e) => onReasoningEffortChange(e.target.value as 'low' | 'medium' | 'high')}
           onClick={(e) => e.stopPropagation()}
           className="rounded bg-white/10 px-1 py-0.5 text-xs text-white/70 outline-none hover:bg-white/20"
           title="Reasoning effort level"
         >
           <option value="low">Low</option>
           <option value="medium">Med</option>
           <option value="high">High</option>
         </select>
         {/* Reasoning button */}
         <button
           onClick={(e) => { e.stopPropagation(); onReasoningRequest(); }}
           className="rounded bg-purple-500/20 px-2 py-0.5 text-xs text-purple-300 transition-colors hover:bg-purple-500/30"
           title="Send reasoning request"
           aria-label="Reasoning request"
         >
           Reason
         </button>
         {/* Existing minimize button */}
         ...
       </div>
       ```
    3. The effort selector and button should be compact (text-xs, minimal padding) to fit the header width
    4. Keep the drag handle class on the outer div unchanged

    **Overlay.tsx -- wire reasoning button:**
    1. Import `useStore` (already imported) and read `reasoningEffort` and `setReasoningEffort`:
       ```typescript
       const reasoningEffort = useStore((state) => state.reasoningEffort);
       const setReasoningEffort = useStore((state) => state.setReasoningEffort);
       ```
    2. Create a `handleReasoningRequest` callback:
       ```typescript
       const handleReasoningRequest = useCallback(() => {
         // Dispatch a custom event that content.tsx will pick up
         window.dispatchEvent(new CustomEvent('reasoning-request', {
           detail: { effort: reasoningEffort }
         }));
       }, [reasoningEffort]);
       ```
    3. Pass new props to OverlayHeader:
       ```tsx
       <OverlayHeader
         onMinimize={handleMinimize}
         onReasoningRequest={handleReasoningRequest}
         reasoningEffort={reasoningEffort}
         onReasoningEffortChange={setReasoningEffort}
       />
       ```
    4. Add `isReasoningRequest` tracking to the LLM response state. Extend the LLMResponse custom event handling:
       - Add a module-level `let isReasoningMode = false;` state in Overlay
       - Actually, this state should live in the content script module scope (content.tsx), not in Overlay. The ResponsePanel just needs to know if the current response is a reasoning response.
       - Better approach: Extend `LLMResponse` type to carry `isReasoning?: boolean` OR detect from status. Simplest: add a local state `isReasoningPending` in Overlay that is set to true when reasoning button is clicked, reset when response completes.

    Actually, the simplest approach: add `isReasoning?: boolean` to the `LLMResponseEventDetail` and `LLMResponse` type in `transcript.ts`. But that modifies a file not owned by this plan. Instead, use a separate event:
    - When reasoning button is clicked, set local state `isReasoningPending = true`
    - When response starts streaming or completes, use that state to show "Reasoning..." indicator
    - Reset on next non-reasoning request

    Add `const [isReasoningPending, setIsReasoningPending] = useState(false);` in Overlay.
    In `handleReasoningRequest`, set `setIsReasoningPending(true)`.
    Listen for `llm-response-update` -- when response status becomes 'complete' or 'error', set `setIsReasoningPending(false)`.
    Pass `isReasoningPending` to ResponsePanel.

    **ResponsePanel.tsx -- add reasoning status indicator:**
    1. Accept new optional prop: `isReasoningPending?: boolean`
    2. In the `StatusIndicator` component, add a reasoning-specific pending state:
       ```typescript
       // Before the existing switch, check reasoning mode
       if (isReasoningPending && (status === 'pending' || status === 'streaming')) {
         return (
           <span className="flex items-center gap-1 text-xs text-purple-300">
             <span className="h-2 w-2 animate-pulse rounded-full bg-purple-400"></span>
             Reasoning...
           </span>
         );
       }
       ```
       The `isReasoningPending` prop needs to flow to `StatusIndicator`. Either pass it as a prop to the memoized StatusIndicator, or add it to ResponsePanel and use it directly.

    3. Pass `isReasoningPending` through ResponsePanel to StatusIndicator:
       - Update `ResponsePanelProps` to include `isReasoningPending?: boolean`
       - Update `StatusIndicator` props to include `isReasoningPending?: boolean`
       - In Overlay.tsx, pass the prop: `<ResponsePanel response={displayResponse} isReasoningPending={isReasoningPending} />`

    4. In ResponsePanel, when showing the pending state with no content, show "Reasoning..." instead of "Processing your question..." when `isReasoningPending`:
       ```tsx
       {response.status === 'pending' && !response.fastHint && !response.fullAnswer && (
         <div className="py-4 text-center text-sm text-white/40 italic">
           {isReasoningPending ? 'Reasoning deeply...' : 'Processing your question...'}
         </div>
       )}
       ```
  </action>
  <verify>
    Run `npx tsc --noEmit` -- should compile without errors.
    Run `npx eslint src/overlay/Overlay.tsx src/overlay/OverlayHeader.tsx src/overlay/ResponsePanel.tsx` -- should have zero lint errors.
  </verify>
  <done>
    - OverlayHeader has a "Reason" button with purple theme styling
    - OverlayHeader has a reasoning effort dropdown (low/med/high) next to the button
    - Clicking "Reason" dispatches a `reasoning-request` custom event with effort detail
    - ResponsePanel shows "Reasoning..." with purple indicator during reasoning requests
    - ResponsePanel shows "Reasoning deeply..." in the pending empty state for reasoning requests
    - All props properly typed and passed through component hierarchy
    - TypeScript compiles without errors
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire reasoning request in content.tsx and update ModelSettings</name>
  <files>
    entrypoints/content.tsx
    src/components/settings/ModelSettings.tsx
  </files>
  <action>
    **content.tsx -- add reasoning request handler:**
    1. Add a new `ReasoningRequestEventDetail` interface:
       ```typescript
       export interface ReasoningRequestEventDetail {
         effort: 'low' | 'medium' | 'high';
       }
       ```

    2. Create `sendReasoningRequest` function (similar to `sendLLMRequest` but with reasoning flags):
       ```typescript
       async function sendReasoningRequest(effort: 'low' | 'medium' | 'high'): Promise<void> {
         const state = useStore.getState();
         if (!state.activeTemplateId) {
           console.warn('AI Interview Assistant: No active template selected');
           return;
         }

         const responseId = crypto.randomUUID();
         activeResponseId = responseId;
         currentLLMResponse = null;
         initLLMResponse(responseId);

         const message: LLMRequestMessage = {
           type: 'LLM_REQUEST',
           responseId,
           question: getRecentTranscript(), // Use recent transcript as the "question"
           recentContext: getRecentTranscript(),
           fullTranscript: getFullTranscript(),
           templateId: state.activeTemplateId,
           isReasoningRequest: true,
           reasoningEffort: effort,
         };

         try {
           await chrome.runtime.sendMessage(message);
         } catch (error) {
           console.error('AI Interview Assistant: Failed to send reasoning request:', error);
         }
       }
       ```

    3. Add event listener for `reasoning-request` custom event:
       In the App component or the content script initialization (where other event listeners are set up), add:
       ```typescript
       window.addEventListener('reasoning-request', ((event: CustomEvent<ReasoningRequestEventDetail>) => {
         sendReasoningRequest(event.detail.effort);
       }) as EventListener);
       ```
       This should be added in the same place where the CaptureProvider is set up, or in the content script's main initialization. Find the appropriate location in the existing code.

    4. Make sure to clean up the event listener on teardown if applicable.

    **ModelSettings.tsx -- add reasoning model visual grouping:**
    1. Import `isReasoningModel` from the LLM service:
       ```typescript
       import { getAvailableModels, isReasoningModel, type ModelInfo } from '../../services/llm';
       ```

    2. In the `ModelSelect` component, split models into three groups instead of two:
       ```typescript
       const { openaiModels, openaiReasoningModels, openrouterModels, openrouterReasoningModels, isCurrentAvailable } = useMemo(() => {
         const allModels = getAvailableModels({ openAI: apiKeys.openAI, openRouter: apiKeys.openRouter });
         const available = allModels.filter((model: ModelInfo) => model.category === category);
         const oaiStandard = available.filter((m: ModelInfo) => m.provider === 'openai' && !isReasoningModel(m.id));
         const oaiReasoning = available.filter((m: ModelInfo) => m.provider === 'openai' && isReasoningModel(m.id));
         const orStandard = available.filter((m: ModelInfo) => m.provider === 'openrouter' && !isReasoningModel(m.id));
         const orReasoning = available.filter((m: ModelInfo) => m.provider === 'openrouter' && isReasoningModel(m.id));
         return {
           openaiModels: oaiStandard,
           openaiReasoningModels: oaiReasoning,
           openrouterModels: orStandard,
           openrouterReasoningModels: orReasoning,
           isCurrentAvailable: available.some((m: ModelInfo) => m.id === currentValue),
         };
       }, [apiKeys.openAI, apiKeys.openRouter, category, currentValue]);
       ```

    3. Update the `<select>` rendering to show reasoning models in separate optgroups:
       ```tsx
       {openaiModels.length > 0 && (
         <optgroup label="OpenAI">
           {openaiModels.map((model: ModelInfo) => (
             <option key={model.id} value={model.id}>{model.name}</option>
           ))}
         </optgroup>
       )}
       {openaiReasoningModels.length > 0 && (
         <optgroup label="OpenAI — Reasoning">
           {openaiReasoningModels.map((model: ModelInfo) => (
             <option key={model.id} value={model.id}>{model.name}</option>
           ))}
         </optgroup>
       )}
       {openrouterModels.length > 0 && (
         <optgroup label="OpenRouter">
           {openrouterModels.map((model: ModelInfo) => (
             <option key={model.id} value={model.id}>{model.name}</option>
           ))}
         </optgroup>
       )}
       {openrouterReasoningModels.length > 0 && (
         <optgroup label="OpenRouter — Reasoning">
           {openrouterReasoningModels.map((model: ModelInfo) => (
             <option key={model.id} value={model.id}>{model.name}</option>
           ))}
         </optgroup>
       )}
       ```

    4. Add a note below the full model select about reasoning models:
       ```tsx
       // In ModelSettings component, after the Full Model ModelSelect:
       <p className="text-xs text-gray-500">
         Reasoning models (o-series, GPT-5) use deep thinking and require 25K+ tokens. Best for comprehensive answers.
       </p>
       ```
  </action>
  <verify>
    Run `npx tsc --noEmit` -- should compile without errors.
    Run `npx eslint entrypoints/content.tsx src/components/settings/ModelSettings.tsx` -- should have zero lint errors.
    Verify in the code:
    1. `reasoning-request` event listener is registered
    2. `sendReasoningRequest` sends LLM_REQUEST with `isReasoningRequest: true` and `reasoningEffort`
    3. ModelSettings groups reasoning models separately with "— Reasoning" label
  </verify>
  <done>
    - content.tsx has `sendReasoningRequest` function that dispatches LLM_REQUEST with reasoning flags
    - content.tsx listens for `reasoning-request` custom event from overlay
    - ModelSettings groups reasoning models in separate optgroups ("OpenAI -- Reasoning", "OpenRouter -- Reasoning")
    - ModelSettings imports and uses `isReasoningModel` to classify models
    - Reasoning models are available for selection in both fast and full model dropdowns
    - TypeScript compiles without errors
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes
2. `npx eslint .` passes (or no new errors in modified files)
3. Visual inspection: OverlayHeader has Reason button + effort dropdown, ResponsePanel has purple Reasoning indicator
4. Code path: Reason button click -> custom event -> content.tsx -> LLM_REQUEST with isReasoningRequest=true -> background single-stream
</verification>

<success_criteria>
- Reasoning button visible in overlay header with purple styling
- Reasoning effort selector (low/med/high) visible next to the button
- Clicking Reason button dispatches reasoning-request event handled by content.tsx
- content.tsx sends LLM_REQUEST with isReasoningRequest=true and reasoningEffort
- ResponsePanel shows "Reasoning..." with purple indicator for reasoning requests
- ModelSettings groups reasoning models separately from standard models
- Zero TypeScript errors
</success_criteria>

<output>
After completion, create `.planning/phases/16-reasoning-models/16-03-SUMMARY.md`
</output>
