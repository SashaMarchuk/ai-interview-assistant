---
phase: 03-transcription
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - entrypoints/offscreen/main.ts
  - entrypoints/background.ts
autonomous: true

must_haves:
  truths:
    - "Offscreen document establishes WebSocket connections for tab and mic audio"
    - "Audio chunks are forwarded to ElevenLabs in real-time"
    - "Service Worker receives transcript updates and merges them chronologically"
    - "Connection errors trigger reconnection with exponential backoff"
  artifacts:
    - path: "entrypoints/offscreen/main.ts"
      provides: "WebSocket transcription connections"
      contains: "ElevenLabsConnection"
    - path: "entrypoints/background.ts"
      provides: "Transcript merging and state management"
      contains: "mergedTranscript"
  key_links:
    - from: "entrypoints/offscreen/main.ts"
      to: "ElevenLabsConnection"
      via: "import from services"
      pattern: "import.*ElevenLabsConnection"
    - from: "entrypoints/offscreen/main.ts"
      to: "chrome.runtime.sendMessage"
      via: "transcript callbacks"
      pattern: "sendMessage.*TRANSCRIPT"
    - from: "entrypoints/background.ts"
      to: "entrypoints/offscreen/main.ts"
      via: "START_TRANSCRIPTION message"
      pattern: "START_TRANSCRIPTION"
---

<objective>
Integrate transcription into Offscreen Document and Service Worker.

Purpose: Connect the WebSocket wrapper to actual audio streams, handle the transcription lifecycle, and merge transcript entries from both sources (tab and mic) chronologically in the Service Worker.

Output: Offscreen document manages dual ElevenLabsConnection instances. Service Worker maintains merged transcript state and broadcasts updates.
</objective>

<execution_context>
@/Users/sasha-marchuk/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sasha-marchuk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-transcription/03-RESEARCH.md
@.planning/phases/03-transcription/03-CONTEXT.md
@.planning/phases/03-transcription/03-01-SUMMARY.md
@entrypoints/offscreen/main.ts
@entrypoints/background.ts
@src/types/messages.ts
@src/services/transcription/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add transcription to Offscreen Document</name>
  <files>entrypoints/offscreen/main.ts</files>
  <action>
Extend offscreen/main.ts to manage ElevenLabs WebSocket connections for transcription.

**Imports:**
Add imports at top:
- ElevenLabsConnection from '../../src/services/transcription'
- Transcription message types from messages.ts

**Module state:**
Add after existing audio state variables:
- let tabTranscription: ElevenLabsConnection | null = null
- let micTranscription: ElevenLabsConnection | null = null
- let transcriptionApiKey: string | null = null

**startTabTranscription function:**
- Takes apiKey parameter
- Creates new ElevenLabsConnection with config { apiKey, source: 'tab' }
- onTranscript callback: sends TRANSCRIPT_PARTIAL or TRANSCRIPT_FINAL message to runtime based on isFinal flag
  - For TRANSCRIPT_FINAL: generate id with crypto.randomUUID(), speaker is 'Interviewer'
- onError callback: sends TRANSCRIPTION_ERROR message with source: 'tab'
- Calls connection.connect()
- Store in tabTranscription

**startMicTranscription function:**
- Takes apiKey parameter
- Creates new ElevenLabsConnection with config { apiKey, source: 'mic' }
- onTranscript callback: sends TRANSCRIPT_PARTIAL or TRANSCRIPT_FINAL message
  - For TRANSCRIPT_FINAL: generate id with crypto.randomUUID(), speaker is 'You'
- onError callback: sends TRANSCRIPTION_ERROR message with source: 'mic'
- Calls connection.connect()
- Store in micTranscription

**stopTranscription function:**
- If tabTranscription exists, call disconnect() and set to null
- If micTranscription exists, call disconnect() and set to null
- Clear transcriptionApiKey

**Modify TAB_AUDIO_CHUNK handler in worklet.port.onmessage:**
- After existing console.log, add: if (tabTranscription) tabTranscription.sendAudio(event.data)
- This forwards PCM chunks to ElevenLabs

**Modify MIC_AUDIO_CHUNK handler in worklet.port.onmessage:**
- After existing console.log, add: if (micTranscription) micTranscription.sendAudio(event.data)

**Add message handlers in onMessage listener:**
- START_TRANSCRIPTION: Store apiKey, call startTabTranscription(apiKey) and startMicTranscription(apiKey), send TRANSCRIPTION_STARTED response
- STOP_TRANSCRIPTION: Call stopTranscription(), send TRANSCRIPTION_STOPPED response

**Modify cleanupAllCapture:**
- Add stopTranscription() call to clean up WebSocket connections on unload
  </action>
  <verify>Run `npm run type-check` - no TypeScript errors. Run `npm run build` - build succeeds.</verify>
  <done>Offscreen document creates and manages dual ElevenLabsConnection instances, forwards audio chunks, handles start/stop commands</done>
</task>

<task type="auto">
  <name>Task 2: Add transcript merging to Service Worker</name>
  <files>entrypoints/background.ts</files>
  <action>
Extend background.ts to manage merged transcript state and handle transcription messages.

**Imports:**
Add TranscriptEntry import from src/types/transcript.ts

**Module state:**
Add after existing imports:
- let mergedTranscript: TranscriptEntry[] = []
- let interimEntries: Map<string, { source: 'tab' | 'mic', text: string, timestamp: number }> = new Map()
  (Tracks interim entries by source to replace when final arrives)

**Helper function addTranscriptEntry(entry: TranscriptEntry):**
- Find correct insertion index to maintain chronological order by timestamp
- Insert entry at that position
- Broadcast TRANSCRIPT_UPDATE message to all contexts (use chrome.runtime.sendMessage for offscreen, will be consumed by content script in Plan 03)

**Add cases to handleMessage switch:**

case 'START_TRANSCRIPTION':
  - Forward message to offscreen document: chrome.runtime.sendMessage({ type: 'START_TRANSCRIPTION', apiKey: message.apiKey })
  - Clear mergedTranscript and interimEntries
  - Return { success: true }

case 'STOP_TRANSCRIPTION':
  - Forward message to offscreen document: chrome.runtime.sendMessage({ type: 'STOP_TRANSCRIPTION' })
  - Return { success: true }

case 'TRANSCRIPTION_STARTED':
  - Log confirmation
  - Return { received: true }

case 'TRANSCRIPTION_STOPPED':
  - Log confirmation
  - Return { received: true }

case 'TRANSCRIPT_PARTIAL':
  - Store in interimEntries Map with key = message.source
  - Log for debugging (interim from source)
  - Return { received: true }

case 'TRANSCRIPT_FINAL':
  - Clear interim entry for this source from interimEntries
  - Create TranscriptEntry: { id: message.id, speaker: message.speaker, text: message.text, timestamp: message.timestamp, isFinal: true }
  - Call addTranscriptEntry(entry)
  - Log for debugging
  - Return { received: true }

case 'TRANSCRIPTION_ERROR':
  - Log error with source
  - Return { received: true }

case 'TRANSCRIPT_UPDATE':
  - This is outbound only, but add case for exhaustive check
  - Return { received: true }

**Note:** Do NOT remove existing TAB_AUDIO_CHUNK and MIC_AUDIO_CHUNK handlers - they're still useful for logging. Just keep them as-is.
  </action>
  <verify>Run `npm run type-check` - no TypeScript errors. Run `npm run build` - build succeeds.</verify>
  <done>Service Worker handles all transcription message types, maintains merged transcript state, broadcasts updates</done>
</task>

</tasks>

<verification>
- [ ] `npm run type-check` passes with no errors
- [ ] `npm run build` completes successfully
- [ ] Offscreen document handles START_TRANSCRIPTION and STOP_TRANSCRIPTION
- [ ] Service Worker handles all transcription message types
- [ ] Audio chunks are forwarded to ElevenLabsConnection when transcription is active
</verification>

<success_criteria>
1. START_TRANSCRIPTION message initiates dual WebSocket connections in offscreen
2. Audio chunks from tab and mic are forwarded to respective ElevenLabs connections
3. Transcript results are merged chronologically in Service Worker
4. STOP_TRANSCRIPTION properly cleans up connections
5. Errors are propagated with appropriate error messages
</success_criteria>

<output>
After completion, create `.planning/phases/03-transcription/03-02-SUMMARY.md`
</output>
