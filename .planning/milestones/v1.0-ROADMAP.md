# Milestone v1.0: MVP

**Status:** SHIPPED 2026-02-03
**Phases:** 1-8
**Total Plans:** 30

## Overview

This roadmap delivered a Chrome MV3 extension providing real-time transcription and dual parallel LLM responses during technical interviews. Features include tab and microphone audio capture, ElevenLabs STT integration, OpenRouter/OpenAI LLM streaming, draggable overlay UI, and comprehensive settings management.

**Execution model:** Phase 1 ran first (foundation). Then 3 parallel tracks ran simultaneously. Phase 7 integrated everything. Phase 8 added OpenAI provider support.

```
Phase 1 (Foundation) ─── SEQUENTIAL, FIRST
         │
         ├──→ Track A: Phase 2→3→4 (Audio→STT→LLM)  ← Terminal 1
         ├──→ Track B: Phase 5 (Overlay UI)          ← Terminal 2
         └──→ Track C: Phase 6 (Settings/Prompts)    ← Terminal 3
                        │
                        ↓
              Phase 7 (Integration) ─── SEQUENTIAL
                        │
                        ↓
              Phase 8 (OpenAI Provider) ─── ENHANCEMENT
```

## Phases

### Phase 1: Foundation

**Goal**: Extension loads successfully with working message passing between Service Worker, Content Script, Offscreen Document, and Popup.
**Depends on**: None
**Plans**: 4 plans

Plans:
- [x] 01-01: Initialize WXT project with React, TypeScript, Tailwind
- [x] 01-02: Implement Service Worker, Popup with message passing
- [x] 01-03: Implement Offscreen Document and Content Script overlay
- [x] 01-04: Verify extension loads and all components communicate

**Details:**
- Chrome MV3 extension with Service Worker
- Offscreen Document for WebSocket connections
- Message passing between SW, Content Script, Offscreen, Popup
- Proper CSP configuration for external WebSocket/API connections

---

### Phase 2: Audio Pipeline

**Goal**: User clicks start and tab audio is captured as PCM chunks flowing through AudioWorklet while audio remains audible.
**Depends on**: Phase 1
**Plans**: 4 plans

Plans:
- [x] 02-01: Message types and PCM AudioWorklet processor
- [x] 02-02: Tab audio capture with passthrough in Offscreen Document
- [x] 02-03: Microphone capture as separate stream
- [x] 02-04: Popup Start/Stop UI and end-to-end verification

**Details:**
- Tab capture via tabCapture API with chromeMediaSource constraint
- Microphone capture as separate stream via getUserMedia
- PCM 16-bit 16kHz conversion via AudioWorklet
- Audio passthrough ensures user hears tab audio during capture

---

### Phase 3: Transcription

**Goal**: User speaks or interviewer speaks and live transcript appears with speaker differentiation.
**Depends on**: Phase 2
**Plans**: 3 plans

Plans:
- [x] 03-01: Transcription types and ElevenLabs WebSocket wrapper
- [x] 03-02: Offscreen transcription and Service Worker merging
- [x] 03-03: Wire transcript to overlay and human verification

**Details:**
- Real-time streaming transcription with < 500ms latency
- ElevenLabs WebSocket with VAD commit strategy
- Speaker diarization ("You" for mic, "Interviewer" for tab)
- Transcript merging by timestamp in Service Worker

---

### Phase 4: LLM Integration

**Goal**: User holds hotkey to capture question, releases to get fast hint immediately plus comprehensive answer streaming.
**Depends on**: Phase 3
**Plans**: 4 plans

Plans:
- [x] 04-01: Install eventsource-parser, LLM types, OpenRouter streaming client
- [x] 04-02: LLM message types and dual parallel streaming in background.ts
- [x] 04-03: Capture mode hook and keyboard handling in content script
- [x] 04-04: Wire LLM responses to overlay, capture indicator, human verification

**Details:**
- Dual parallel LLM requests (fast hint + full answer)
- OpenRouter API with SSE streaming via eventsource-parser
- Hold-to-capture and highlight-to-send keyboard modes
- Service Worker keep-alive during long streams

---

### Phase 5: Overlay UI (Track B — parallel)

**Goal**: User sees professional floating overlay with transcript and dual response panels that can be positioned and resized.
**Depends on**: Phase 1 only
**Plans**: 4 plans

Plans:
- [x] 05-01: Install deps, create types, hooks, Tailwind Shadow DOM fixes
- [x] 05-02: Overlay container with react-rnd drag/resize
- [x] 05-03: TranscriptPanel and ResponsePanel components
- [x] 05-04: Integration with mock data and visual verification

**Details:**
- Shadow DOM isolation from page styles
- Draggable and resizable overlay via react-rnd
- Transparent glassmorphism with adjustable blur
- Minimize to draggable AI button

---

### Phase 6: Prompts & Settings (Track C — parallel)

**Goal**: User configures API keys, selects models, and switches between prompt templates for different interview types.
**Depends on**: Phase 1 only
**Plans**: 4 plans

Plans:
- [x] 06-01: Zustand store with settings slice, templates slice, chrome.storage persistence
- [x] 06-02: Settings UI (API keys, models, hotkeys, blur level)
- [x] 06-03: Template Manager UI (list, editor, CRUD operations)
- [x] 06-04: Human verification of complete settings flow

**Details:**
- Zustand store with chrome.storage.local persistence
- API key management for ElevenLabs and OpenRouter
- Multiple prompt templates (System Design, Coding, Behavioral)
- Per-template model override support

---

### Phase 7: Integration

**Goal**: Wire all parallel tracks together with graceful degradation and verify end-to-end functionality.
**Depends on**: Phases 4, 5, 6 all complete
**Plans**: 4 plans

Plans:
- [x] 07-01: Graceful degradation UI and health indicator
- [x] 07-02: Connection state broadcasting and LLM retry logic
- [x] 07-03: Wire connection state to UI and end-to-end verification
- [x] 07-04: Toggle mode for capture hotkey (KEY-03)

**Details:**
- Graceful degradation when API keys missing
- Health indicators for service issues
- LLM retry logic (3 retries with exponential backoff)
- Toggle mode as alternative to hold-to-capture

---

### Phase 8: OpenAI Provider Support

**Goal**: Add OpenAI as alternative LLM provider to OpenRouter with smart model availability based on configured API keys.
**Depends on**: Phase 7
**Plans**: 3 plans

Plans:
- [x] 08-01: Provider types, interface, OpenRouter and OpenAI adapters
- [x] 08-02: Store updates and settings UI for OpenAI key
- [x] 08-03: Background.ts integration and end-to-end verification

**Details:**
- Provider abstraction layer with LLMProvider interface
- OpenAI direct API support with SSE streaming
- Smart model availability based on configured API keys
- Mixed provider configurations (fast=OpenRouter, full=OpenAI)

---

## Milestone Summary

**Key Decisions:**

| Decision | Rationale |
|----------|-----------|
| 8-phase structure with parallel tracks | Phase 1 first, then Tracks A/B/C in parallel, Phase 7 integrates |
| WXT 0.19.x for Node 18 compatibility | Latest WXT 0.20.x requires Node 20+ |
| Tailwind v4 with CSS-first config | No tailwind.config.ts needed |
| Shadow DOM via createShadowRootUi | CSS isolation from Google Meet page styles |
| Split AudioChunkMessage types | TypeScript narrowing works better with separate types |
| webext-zustand for cross-context sync | Enables chrome.storage persistence with Zustand |
| eventsource-parser for SSE | Reliable SSE parsing for OpenRouter/OpenAI streaming |
| LLMProvider interface | Strategy pattern enables multiple providers |

**Issues Resolved:**

- UI flickering/capture loop fixed with synchronous ref tracking
- LLM response mixing prevented with request-scoped state
- Shadow DOM CSS isolation with inline Tailwind v4 @theme
- Service Worker keep-alive during long LLM streams

**Technical Debt Incurred:**

- Phase 03 missing formal VERIFICATION.md (verified via dependencies)
- OpenRouterClient.ts kept for backward compatibility (deprecated)

---

*For current project status, see .planning/ROADMAP.md*

---

*Archived: 2026-02-03 as part of v1.0 milestone completion*
